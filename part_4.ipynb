{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 â€“ Design Challenge (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "class FloatDict(defaultdict):\n",
    "    def __init__(self):\n",
    "        super().__init__(float)\n",
    "\n",
    "\n",
    "class AveragedPerceptron:\n",
    "    def __init__(self):\n",
    "        # self.weights = defaultdict(lambda: defaultdict(float))\n",
    "        self.weights = defaultdict(FloatDict)\n",
    "        self.totals = defaultdict(float)\n",
    "        self.timestamps = defaultdict(int)\n",
    "        self.i = 0  # total updates\n",
    "\n",
    "    def predict(self, features):\n",
    "        scores = defaultdict(float)\n",
    "        for feat, value in features.items():\n",
    "            if value == 0 or feat not in self.weights:\n",
    "                continue\n",
    "            for label, weight in self.weights[feat].items():\n",
    "                scores[label] += value * weight\n",
    "        return max(scores, key=scores.get) if scores else 'O'\n",
    "\n",
    "    def update(self, truth, guess, features):\n",
    "        def upd_feat(feat, label, value):\n",
    "            param = (feat, label)\n",
    "            self.totals[param] += (self.i - self.timestamps[param]) * self.weights[feat][label]\n",
    "            self.timestamps[param] = self.i\n",
    "            self.weights[feat][label] += value\n",
    "\n",
    "        self.i += 1\n",
    "        if truth == guess:\n",
    "            return\n",
    "        for feat in features:\n",
    "            upd_feat(feat, truth, 1.0)\n",
    "            upd_feat(feat, guess, -1.0)\n",
    "\n",
    "    def average_weights(self):\n",
    "        for feat, weights in self.weights.items():\n",
    "            for label in weights:\n",
    "                param = (feat, label)\n",
    "                total = self.totals[param] + (self.i - self.timestamps[param]) * weights[label]\n",
    "                averaged = total / self.i\n",
    "                if averaged:\n",
    "                    self.weights[feat][label] = averaged\n",
    "                else:\n",
    "                    del self.weights[feat][label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def extract_features(sentence, index):\n",
    "    word = sentence[index]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower=' + word.lower(): 1.0,\n",
    "        'word[-3:]=' + word[-3:]: 1.0,\n",
    "        'word[-2:]=' + word[-2:]: 1.0,\n",
    "        'word.isupper=' + str(word.isupper()): 1.0,\n",
    "        'word.istitle=' + str(word.istitle()): 1.0,\n",
    "        'word.isdigit=' + str(word.isdigit()): 1.0,\n",
    "        'word.shape=' + word_shape(word): 1.0,\n",
    "        'word.has_hyphen=' + str('-' in word): 1.0,\n",
    "        'word.has_digit=' + str(any(char.isdigit() for char in word)): 1.0,\n",
    "        'word.has_punct=' + str(any(char in string.punctuation for char in word)): 1.0,\n",
    "    }\n",
    "\n",
    "    if index > 0:\n",
    "        prev = sentence[index - 1]\n",
    "        features.update({\n",
    "            '-1:word.lower=' + prev.lower(): 1.0,\n",
    "            '-1:word.istitle=' + str(prev.istitle()): 1.0,\n",
    "            '-1:word.shape=' + word_shape(prev): 1.0,\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = 1.0\n",
    "\n",
    "    if index < len(sentence) - 1:\n",
    "        next = sentence[index + 1]\n",
    "        features.update({\n",
    "            '+1:word.lower=' + next.lower(): 1.0,\n",
    "            '+1:word.istitle=' + str(next.istitle()): 1.0,\n",
    "            '+1:word.shape=' + word_shape(next): 1.0,\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = 1.0\n",
    "\n",
    "    return features\n",
    "\n",
    "def word_shape(word):\n",
    "    shape = ''\n",
    "    for char in word:\n",
    "        if char.isupper():\n",
    "            shape += 'X'\n",
    "        elif char.islower():\n",
    "            shape += 'x'\n",
    "        elif char.isdigit():\n",
    "            shape += 'd'\n",
    "        else:\n",
    "            shape += char\n",
    "    return shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_perceptron(dataset, epochs=5):\n",
    "    model = AveragedPerceptron()\n",
    "    for _ in range(epochs):\n",
    "        random.shuffle(dataset)\n",
    "        for sentence, tags in dataset:\n",
    "            for i in range(len(sentence)):\n",
    "                features = extract_features(sentence, i)\n",
    "                pred = model.predict(features)\n",
    "                model.update(tags[i], pred, features)\n",
    "    model.average_weights()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    sentences, labels = [], []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sent, labs = [], []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if sent:\n",
    "                    sentences.append(sent)\n",
    "                    labels.append(labs)\n",
    "                    sent, labs = [], []\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) == 2:\n",
    "                token, label = parts\n",
    "            else:\n",
    "                token, label = parts[0], 'O'  # fallback if label is missing\n",
    "            sent.append(token)\n",
    "            labs.append(label)\n",
    "        if sent:\n",
    "            sentences.append(sent)\n",
    "            labels.append(labs)\n",
    "    return list(zip(sentences, labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_unlabeled_data(file_path):\n",
    "    sentences = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        sent = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if sent:\n",
    "                    sentences.append(sent)\n",
    "                    sent = []\n",
    "                continue\n",
    "            sent.append(line)\n",
    "        if sent:\n",
    "            sentences.append(sent)\n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"EN/train\"\n",
    "dev_in_file = \"EN/dev.in\"\n",
    "gold_file = \"EN/dev.out\"\n",
    "\n",
    "train_data = read_data(train_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_perceptron(train_data, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to part_4_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import dill\n",
    "\n",
    "def save_model(model, filename='part_4_model.pkl'):\n",
    "    with open(filename, 'wb') as f:\n",
    "        dill.dump(model, f)\n",
    "    print(f\"Model saved to {filename}\")\n",
    "\n",
    "save_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from part_4_model.pkl\n"
     ]
    }
   ],
   "source": [
    "def load_model(filename='model.pkl'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        model = dill.load(f)\n",
    "    print(f\"Model loaded from {filename}\")\n",
    "    return model\n",
    "model = load_model(\"part_4_model.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to write and evaluate dev predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sentences = read_unlabeled_data(dev_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"EN/dev.p4.out\", 'w', encoding='utf-8') as out_f:\n",
    "    for sent in dev_sentences:\n",
    "        for i in range(len(sent)):\n",
    "            feats = extract_features(sent, i)\n",
    "            pred = model.predict(feats)\n",
    "            out_f.write(f\"{sent[i]} {pred}\\n\")\n",
    "        out_f.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "with open(\"eval_log.txt\", \"a\") as f:\n",
    "    f.write(f\"\\n----- Run at {datetime.datetime.now()} -----\\n\")\n",
    "\n",
    "!python EvalScript/evalResult.py EN/dev.out EN/dev.p4.out >> eval_log.txt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to write test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_file = \"EN/test.in\"\n",
    "test_sentences = read_unlabeled_data(test_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"EN/test.p4.out\", 'w', encoding='utf-8') as out_f:\n",
    "    for sent in test_sentences:\n",
    "        for i in range(len(sent)):\n",
    "            feats = extract_features(sent, i)\n",
    "            pred = model.predict(feats)\n",
    "            out_f.write(f\"{sent[i]} {pred}\\n\")\n",
    "        out_f.write(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
